{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"digitClassifier.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UX0UdjB3is0k"},"source":["## Import Libraries"]},{"cell_type":"code","metadata":{"id":"LnRgRIsgVfUQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614718565114,"user_tz":-120,"elapsed":2542,"user":{"displayName":"George Rouvalis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOquqA-iZ8D0tVtvosCKyeJZFqyD7he_S0lJgp=s64","userId":"07262416081964161526"}},"outputId":"154b3052-dc9e-48e5-8933-cbf31f01a0e5"},"source":["import numpy as np\r\n","from numpy import mean\r\n","from numpy import std\r\n","from matplotlib import pyplot\r\n","from keras.datasets import mnist\r\n","from keras.utils import to_categorical\r\n","from keras.models import Sequential\r\n","from keras.layers import Conv2D\r\n","from keras.layers import MaxPooling2D\r\n","from keras.layers import Dense\r\n","from keras.layers import Flatten\r\n","from keras.layers import Dropout\r\n","from keras.optimizers import SGD,RMSprop\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\r\n","import cv2\r\n","\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')\r\n","\r\n","import os\r\n","os.chdir(\"drive/My Drive/Colab Notebooks/ML/\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cfDG-ODXiv8l"},"source":["### Load MNIST dataset\r\n","\r\n","- Loading data from keras library\r\n","- Reshaping dataset to have a single channel\r\n","- Converting categorical data to numerical data using one hot encoding"]},{"cell_type":"code","metadata":{"id":"3G3u5i0dVjqL"},"source":["# Load dataset\r\n","(trainX, trainY), (testX, testY) = mnist.load_data()\r\n"," \r\n","# Reshape dataset\r\n","trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\r\n","testX = testX.reshape((testX.shape[0], 28, 28, 1))\r\n","\r\n","# One hot encode target values\r\n","trainY = to_categorical(trainY)\r\n","testY = to_categorical(testY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5fRidvAtlO0p"},"source":["### Pixels Scaling\r\n","\r\n","**Normalization**: Pixel values are scaled to the range 0-1\r\n","\r\n","Neural network models often cannot be trained on raw pixel values, such as pixel values in the range of 0 to 255.\r\n","\r\n","The reason is that the network uses a weighted sum of inputs, and for the network to both be stable and train effectively, weights should be kept small.\r\n","\r\n","Instead, the pixel values must be scaled prior to training.\r\n","\r\n","Normalization is often the default approach as we can assume pixel values are always in the range 0-255, making the procedure very simple and efficient to implement."]},{"cell_type":"code","metadata":{"id":"End-gJcgV4Fz"},"source":["# Convert from integers to floats\r\n","trainX = trainX.astype('float32')\r\n","testX = testX.astype('float32')\r\n","\r\n","# Normalize to range 0-1\r\n","trainX = trainX / 255.0\r\n","testX = testX / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cfbwmv0si7Vz"},"source":["### CNN model definition\r\n","\r\n","- #### Configuration\r\n","  - **1 2D Convolution Layer**: (3,3) is the dimensionality space of output, RELU is the activation function. HE initializer performs better than normal thats why is selected.\r\n","  - **1 Flatten Layer**: Flatten the data so they can be passed to dense layer (keeping 1 dimension)\r\n","  - **2 Dense Layers**: Dense layers are used when association can exist among any feature to any other feature in data point. Since between two layers of size n1 and n2, there can n1∗n2 connections and these are referred to as Dense. The first one contains a RELU activation function while the second is the softmax layer.\r\n","\r\n","- #### Compilation\r\n","  - **Optimizer**: Gradient descent is a good one for general purposes ( Adam can be used as well )  \r\n","  - **Loss function**: Since we’re using a Softmax output layer, we’ll use the Cross-Entropy loss"]},{"cell_type":"code","metadata":{"id":"uGK8trxii4H_"},"source":["def define_model():\r\n","    model = Sequential()\r\n","    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\r\n","    model.add(MaxPooling2D((2, 2)))\r\n","    model.add(Flatten())\r\n","    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\r\n","    model.add(Dense(10, activation='softmax'))\r\n"," \r\n","    # model compilation\r\n","    opt = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0, centered=False,name=\"RMSprop\")\r\n","    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\r\n","    return model\r\n","\r\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \r\n","                                            patience=3, \r\n","                                            verbose=1, \r\n","                                            factor=0.5, \r\n","                                            min_lr=0.00001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uWBuFRVFaicb"},"source":["## Data Augmentation\r\n","\r\n","In order to avoid over-fitting problem, we need to expand artificially our handwritten digit dataset.\r\n","Data augmentation is a strategy that enables to significantly increase the diversity of data available for our training model. "]},{"cell_type":"code","metadata":{"id":"BJuLkoWz0UlN"},"source":["def adjust_gamma(image):\r\n","    img = np.power(image/float(np.max(image)), 1.5)\r\n","\r\n","    return img\r\n","\r\n","def my_preprocessing_func(img):\r\n","    img = adjust_gamma(img)\r\n","\r\n","    image = np.array(img)\r\n","    return image / 255\r\n","\r\n","datagen = ImageDataGenerator(\r\n","        featurewise_center=True,  # set input mean to 0 over the dataset\r\n","        samplewise_center=True,  # set each sample mean to 0\r\n","        featurewise_std_normalization=True,  # divide inputs by std of the dataset\r\n","        samplewise_std_normalization=True,  # divide each input by its std\r\n","        zca_whitening=False,  # apply ZCA whitening\r\n","        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\r\n","        zoom_range = 0.1, # Randomly zoom image \r\n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\r\n","        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\r\n","        horizontal_flip=False,  # randomly flip images\r\n","        vertical_flip=False,    # randomly flip images\r\n","        preprocessing_function=my_preprocessing_func)  \r\n","datagen.fit(trainX)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sLXH3nq5abvn"},"source":["## Dataset Expansion\r\n","\r\n","Expand the original dataset with the augmented MNIST images."]},{"cell_type":"code","metadata":{"id":"sOVAlfiFmBK0"},"source":["counter = 0\r\n","batch_size=9\r\n","original_samples = trainX.shape[0]\r\n","\r\n","for X_batch, y_batch in datagen.flow(trainX, trainY, batch_size):\r\n","    trainX = np.concatenate((trainX, X_batch), axis=0)\r\n","    trainY = np.concatenate((trainY, y_batch), axis=0)\r\n","\r\n","    if counter == 1000:\r\n","        break\r\n","\r\n","    counter += 1\r\n","\r\n","    # # create a grid of 3x3 images\r\n","    # for i in range(0, 9):\r\n","        \r\n","    #     pyplot.subplot(330 + 1 + i)\r\n","    #     pyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\r\n","    # pyplot.show()\r\n","    # break\r\n","    # ###########\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MZFi4poki_wg"},"source":["### Model Evaluation\r\n","\r\n","Model was finally fitted to the original dataset, merged with the augmented.\r\n","Validation was performed on the validation data.\r\n","\r\n","The steps per epoch was calculated as train-length / batch-size, since this uses all of the data points, one batch size worth at a time.\r\n","\r\n","When the metric had stopped improving the learning rate was reduced."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brUuLgTGWh6m","executionInfo":{"status":"ok","timestamp":1614719052901,"user_tz":-120,"elapsed":490313,"user":{"displayName":"George Rouvalis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOquqA-iZ8D0tVtvosCKyeJZFqyD7he_S0lJgp=s64","userId":"07262416081964161526"}},"outputId":"5c51fd1a-15e4-43b5-af0d-44a4c0634fd7"},"source":["model = define_model()\r\n","history = model.fit(trainX, trainY, batch_size=32, validation_data=(testX, testY),steps_per_epoch=len(trainX) / 32, epochs=10, callbacks=[learning_rate_reduction], verbose=1)\r\n","_, acc = model.evaluate(testX, testY, verbose=0)\r\n","print('> %.3f' % (acc * 100.0))\r\n","\r\n","model.save(\"./mymodel.h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","2156/2156 [==============================] - 44s 20ms/step - loss: 0.8638 - accuracy: 0.8334 - val_loss: 0.0748 - val_accuracy: 0.9765\n","Epoch 2/10\n","2156/2156 [==============================] - 44s 20ms/step - loss: 0.2748 - accuracy: 0.9520 - val_loss: 0.0630 - val_accuracy: 0.9813\n","Epoch 3/10\n","2156/2156 [==============================] - 42s 20ms/step - loss: 0.2471 - accuracy: 0.9647 - val_loss: 0.0534 - val_accuracy: 0.9832\n","Epoch 4/10\n","2156/2156 [==============================] - 43s 20ms/step - loss: 0.2273 - accuracy: 0.9704 - val_loss: 0.0532 - val_accuracy: 0.9836\n","Epoch 5/10\n","2156/2156 [==============================] - 43s 20ms/step - loss: 0.2424 - accuracy: 0.9752 - val_loss: 0.0536 - val_accuracy: 0.9827\n","Epoch 6/10\n","2156/2156 [==============================] - 45s 21ms/step - loss: 0.1968 - accuracy: 0.9780 - val_loss: 0.0530 - val_accuracy: 0.9833\n","Epoch 7/10\n","2156/2156 [==============================] - 43s 20ms/step - loss: 0.2105 - accuracy: 0.9787 - val_loss: 0.0505 - val_accuracy: 0.9846\n","Epoch 8/10\n","2156/2156 [==============================] - 43s 20ms/step - loss: 0.2009 - accuracy: 0.9812 - val_loss: 0.0654 - val_accuracy: 0.9824\n","Epoch 9/10\n","2156/2156 [==============================] - 43s 20ms/step - loss: 0.1764 - accuracy: 0.9832 - val_loss: 0.0578 - val_accuracy: 0.9835\n","Epoch 10/10\n","2156/2156 [==============================] - 44s 20ms/step - loss: 0.1851 - accuracy: 0.9839 - val_loss: 0.0582 - val_accuracy: 0.9836\n","\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","> 98.360\n"],"name":"stdout"}]}]}